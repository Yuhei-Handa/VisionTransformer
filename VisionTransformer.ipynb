{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "transform =torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(image_size), torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_datasets = torchvision.datasets.CIFAR100(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_datasets = torchvision.datasets.CIFAR100(\n",
    "    root=\"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_datasets, batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_datasets, batch_size=32, shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(train_dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
       "        [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
       "        [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
       "        ...,\n",
       "        [0.3922, 0.3922, 0.3922,  ..., 0.4588, 0.4588, 0.4588],\n",
       "        [0.3922, 0.3922, 0.3922,  ..., 0.4588, 0.4588, 0.4588],\n",
       "        [0.3922, 0.3922, 0.3922,  ..., 0.4588, 0.4588, 0.4588]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "patch_size = 2\n",
    "num_channel = 3\n",
    "batch_size = 32\n",
    "patch_window = torch.ones((patch_size, patch_size), dtype=torch.long)\n",
    "patch_window = patch_window.expand(num_channel, patch_size, patch_size).unsqueeze(0).expand(batch_size, num_channel, patch_size, patch_size)\n",
    "\n",
    "\n",
    "patch = image[:, :, :2, :2] * patch_window\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "position_ids = torch.tensor(list(range(10)), dtype=torch.long).expand(4, -1)\n",
    "\n",
    "embed = nn.Embedding(10, 5)\n",
    "\n",
    "print(embed(position_ids).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "cls_embedding = nn.Embedding(1, 768)(torch.tensor(0))\n",
    "print(cls_embedding.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3137, 0.3137],\n",
      "          [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3137, 0.3137],\n",
      "          [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3137, 0.3137],\n",
      "          ...,\n",
      "          [0.2157, 0.2157, 0.2157,  ..., 0.1765, 0.1765, 0.1765],\n",
      "          [0.2157, 0.2157, 0.2157,  ..., 0.1765, 0.1765, 0.1765],\n",
      "          [0.2157, 0.2157, 0.2157,  ..., 0.1765, 0.1765, 0.1765]],\n",
      "\n",
      "         [[0.3451, 0.3451, 0.3451,  ..., 0.3294, 0.3294, 0.3294],\n",
      "          [0.3451, 0.3451, 0.3451,  ..., 0.3294, 0.3294, 0.3294],\n",
      "          [0.3451, 0.3451, 0.3451,  ..., 0.3294, 0.3294, 0.3294],\n",
      "          ...,\n",
      "          [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "          [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647],\n",
      "          [0.1922, 0.1922, 0.1922,  ..., 0.1647, 0.1647, 0.1647]],\n",
      "\n",
      "         [[0.2235, 0.2235, 0.2235,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2235, 0.2235, 0.2235,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2235, 0.2235, 0.2235,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          ...,\n",
      "          [0.1294, 0.1294, 0.1294,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.1294, 0.1294, 0.1294,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.1294, 0.1294, 0.1294,  ..., 0.0941, 0.0941, 0.0941]]],\n",
      "\n",
      "\n",
      "        [[[0.5843, 0.5843, 0.5843,  ..., 0.2706, 0.2706, 0.2706],\n",
      "          [0.5843, 0.5843, 0.5843,  ..., 0.2706, 0.2706, 0.2706],\n",
      "          [0.5843, 0.5843, 0.5843,  ..., 0.2706, 0.2706, 0.2706],\n",
      "          ...,\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.2392, 0.2392, 0.2392],\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.2392, 0.2392, 0.2392],\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.2392, 0.2392, 0.2392]],\n",
      "\n",
      "         [[0.5373, 0.5373, 0.5373,  ..., 0.2471, 0.2471, 0.2471],\n",
      "          [0.5373, 0.5373, 0.5373,  ..., 0.2471, 0.2471, 0.2471],\n",
      "          [0.5373, 0.5373, 0.5373,  ..., 0.2471, 0.2471, 0.2471],\n",
      "          ...,\n",
      "          [0.4902, 0.4902, 0.4902,  ..., 0.2157, 0.2157, 0.2157],\n",
      "          [0.4902, 0.4902, 0.4902,  ..., 0.2157, 0.2157, 0.2157],\n",
      "          [0.4902, 0.4902, 0.4902,  ..., 0.2157, 0.2157, 0.2157]],\n",
      "\n",
      "         [[0.4549, 0.4549, 0.4549,  ..., 0.1686, 0.1686, 0.1686],\n",
      "          [0.4549, 0.4549, 0.4549,  ..., 0.1686, 0.1686, 0.1686],\n",
      "          [0.4549, 0.4549, 0.4549,  ..., 0.1686, 0.1686, 0.1686],\n",
      "          ...,\n",
      "          [0.4157, 0.4157, 0.4157,  ..., 0.1529, 0.1529, 0.1529],\n",
      "          [0.4157, 0.4157, 0.4157,  ..., 0.1529, 0.1529, 0.1529],\n",
      "          [0.4157, 0.4157, 0.4157,  ..., 0.1529, 0.1529, 0.1529]]],\n",
      "\n",
      "\n",
      "        [[[0.2784, 0.2784, 0.2784,  ..., 0.7373, 0.7373, 0.7373],\n",
      "          [0.2784, 0.2784, 0.2784,  ..., 0.7373, 0.7373, 0.7373],\n",
      "          [0.2784, 0.2784, 0.2784,  ..., 0.7373, 0.7373, 0.7373],\n",
      "          ...,\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.1961, 0.1961, 0.1961],\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.1961, 0.1961, 0.1961],\n",
      "          [0.6039, 0.6039, 0.6039,  ..., 0.1961, 0.1961, 0.1961]],\n",
      "\n",
      "         [[0.2863, 0.2863, 0.2863,  ..., 0.8353, 0.8353, 0.8353],\n",
      "          [0.2863, 0.2863, 0.2863,  ..., 0.8353, 0.8353, 0.8353],\n",
      "          [0.2863, 0.2863, 0.2863,  ..., 0.8353, 0.8353, 0.8353],\n",
      "          ...,\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.2275, 0.2275, 0.2275],\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.2275, 0.2275, 0.2275],\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.2275, 0.2275, 0.2275]],\n",
      "\n",
      "         [[0.2353, 0.2353, 0.2353,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.2353, 0.2353, 0.2353,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.2353, 0.2353, 0.2353,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          ...,\n",
      "          [0.5569, 0.5569, 0.5569,  ..., 0.1569, 0.1569, 0.1569],\n",
      "          [0.5569, 0.5569, 0.5569,  ..., 0.1569, 0.1569, 0.1569],\n",
      "          [0.5569, 0.5569, 0.5569,  ..., 0.1569, 0.1569, 0.1569]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          ...,\n",
      "          [0.0980, 0.0980, 0.0980,  ..., 0.1373, 0.1373, 0.1373],\n",
      "          [0.0980, 0.0980, 0.0980,  ..., 0.1373, 0.1373, 0.1373],\n",
      "          [0.0980, 0.0980, 0.0980,  ..., 0.1373, 0.1373, 0.1373]],\n",
      "\n",
      "         [[0.4196, 0.4196, 0.4196,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.4196, 0.4196, 0.4196,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.4196, 0.4196, 0.4196,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          ...,\n",
      "          [0.6745, 0.6745, 0.6745,  ..., 0.4706, 0.4706, 0.4706],\n",
      "          [0.6745, 0.6745, 0.6745,  ..., 0.4706, 0.4706, 0.4706],\n",
      "          [0.6745, 0.6745, 0.6745,  ..., 0.4706, 0.4706, 0.4706]],\n",
      "\n",
      "         [[0.7020, 0.7020, 0.7020,  ..., 0.7294, 0.7294, 0.7294],\n",
      "          [0.7020, 0.7020, 0.7020,  ..., 0.7294, 0.7294, 0.7294],\n",
      "          [0.7020, 0.7020, 0.7020,  ..., 0.7294, 0.7294, 0.7294],\n",
      "          ...,\n",
      "          [0.8314, 0.8314, 0.8314,  ..., 0.5569, 0.5569, 0.5569],\n",
      "          [0.8314, 0.8314, 0.8314,  ..., 0.5569, 0.5569, 0.5569],\n",
      "          [0.8314, 0.8314, 0.8314,  ..., 0.5569, 0.5569, 0.5569]]],\n",
      "\n",
      "\n",
      "        [[[0.2549, 0.2549, 0.2549,  ..., 0.2157, 0.2157, 0.2157],\n",
      "          [0.2549, 0.2549, 0.2549,  ..., 0.2157, 0.2157, 0.2157],\n",
      "          [0.2549, 0.2549, 0.2549,  ..., 0.2157, 0.2157, 0.2157],\n",
      "          ...,\n",
      "          [0.2980, 0.2980, 0.2980,  ..., 0.1608, 0.1608, 0.1608],\n",
      "          [0.2980, 0.2980, 0.2980,  ..., 0.1608, 0.1608, 0.1608],\n",
      "          [0.2980, 0.2980, 0.2980,  ..., 0.1608, 0.1608, 0.1608]],\n",
      "\n",
      "         [[0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0667, 0.0667],\n",
      "          [0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0667, 0.0667],\n",
      "          [0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0667, 0.0667],\n",
      "          ...,\n",
      "          [0.1608, 0.1608, 0.1608,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.1608, 0.1608, 0.1608,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.1608, 0.1608, 0.1608,  ..., 0.0235, 0.0235, 0.0235]],\n",
      "\n",
      "         [[0.0784, 0.0784, 0.0784,  ..., 0.1098, 0.1098, 0.1098],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.1098, 0.1098, 0.1098],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.1098, 0.1098, 0.1098],\n",
      "          ...,\n",
      "          [0.1490, 0.1490, 0.1490,  ..., 0.0784, 0.0784, 0.0784],\n",
      "          [0.1490, 0.1490, 0.1490,  ..., 0.0784, 0.0784, 0.0784],\n",
      "          [0.1490, 0.1490, 0.1490,  ..., 0.0784, 0.0784, 0.0784]]],\n",
      "\n",
      "\n",
      "        [[[0.5686, 0.5686, 0.5686,  ..., 0.0980, 0.0980, 0.0980],\n",
      "          [0.5686, 0.5686, 0.5686,  ..., 0.0980, 0.0980, 0.0980],\n",
      "          [0.5686, 0.5686, 0.5686,  ..., 0.0980, 0.0980, 0.0980],\n",
      "          ...,\n",
      "          [0.3804, 0.3804, 0.3804,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.3804, 0.3804, 0.3804,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.3804, 0.3804, 0.3804,  ..., 0.0941, 0.0941, 0.0941]],\n",
      "\n",
      "         [[0.5216, 0.5216, 0.5216,  ..., 0.0706, 0.0706, 0.0706],\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.0706, 0.0706, 0.0706],\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.0706, 0.0706, 0.0706],\n",
      "          ...,\n",
      "          [0.4000, 0.4000, 0.4000,  ..., 0.0667, 0.0667, 0.0667],\n",
      "          [0.4000, 0.4000, 0.4000,  ..., 0.0667, 0.0667, 0.0667],\n",
      "          [0.4000, 0.4000, 0.4000,  ..., 0.0667, 0.0667, 0.0667]],\n",
      "\n",
      "         [[0.4706, 0.4706, 0.4706,  ..., 0.0627, 0.0627, 0.0627],\n",
      "          [0.4706, 0.4706, 0.4706,  ..., 0.0627, 0.0627, 0.0627],\n",
      "          [0.4706, 0.4706, 0.4706,  ..., 0.0627, 0.0627, 0.0627],\n",
      "          ...,\n",
      "          [0.3569, 0.3569, 0.3569,  ..., 0.0588, 0.0588, 0.0588],\n",
      "          [0.3569, 0.3569, 0.3569,  ..., 0.0588, 0.0588, 0.0588],\n",
      "          [0.3569, 0.3569, 0.3569,  ..., 0.0588, 0.0588, 0.0588]]]]), tensor([49, 80,  0, 18, 25, 15, 28, 74, 63,  1,  8, 97,  6, 71,  2, 48, 49, 74,\n",
      "        13,  9,  9, 73, 14, 58, 80, 48, 70, 72, 25, 30, 42, 24])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class VisonTransformer(nn.Module):\n",
    "    def __init__(self,batch_size, image_size, num_channel, patch_size, embed_hidden_size, num_layer, num_head):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_channel = num_channel\n",
    "        self.num_patch = int((image_size / patch_size) * (image / patch_size))\n",
    "        self.num_token = self.num_patch + 1\n",
    "        self.cls_id = torch.tensor(0, dtype=torch.long)\n",
    "        self.cls_embedding = nn.Embedding(1, embed_hidden_size)\n",
    "        self.embed_hidden_size = embed_hidden_size\n",
    "        self.positional_embedding = nn.Embedding(self.num_token, embed_hidden_size)\n",
    "        self.image_embedding = nn.Linear(patch_size * patch_size * self.num_patch, embed_hidden_size)\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "\n",
    "    def image_to_token(self, images, patch_size):\n",
    "        batch_size, num_channel, width, height = self.batch_size, self.num_channel, self.image_size, self.image_size\n",
    "        num_patch = self.num_patch\n",
    "        num_pixel_in_patch = patch_size * patch_size\n",
    "\n",
    "        patch_window = torch.ones((patch_size, patch_size), dtype=torch.long)\n",
    "        patch_window = patch_window.unsqueeze(0).expand(num_channel, patch_size, patch_size)\\\n",
    "            .unsqueeze(0).expand(batch_size, num_channel, patch_size, patch_size)\n",
    "        \n",
    "        token_list = torch.tensor([])\n",
    "\n",
    "        for row_idx, in range(0, width, patch_size):\n",
    "            for col_idx in range(0, height, patch_size):\n",
    "                token_list = torch.concat([token_list, \\\n",
    "                                           images[row_idx:row_idx + patch_size, col_idx:col_idx + patch_size]], dim=0)\n",
    "                \n",
    "        \n",
    "        token_list = token_list.transpose(1, 0, 2, 3, 4).view(batch_size, num_patch, num_channel, -1)\n",
    "        token_list = token_list.view(batch_size, num_patch, -1)\n",
    "\n",
    "        return token_list\n",
    "    \n",
    "    def positional_encoding(self, num_token):\n",
    "        position_ids = torch.tensor(list(range(num_token)), dtype=torch.long).expand(self.batch_size, -1)\n",
    "        positional_embeds = self.positional_embedding(position_ids)\n",
    "\n",
    "        return positional_embeds\n",
    "\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \n",
    "        cls_tokens = self.cls_embedding(self.cls_id).unsqueeze(0).expand(batch_size, 1, -1)\n",
    "        image_tokens = self.image_to_token(images, self.patch_size)\n",
    "        tokens = torch.concat([cls_tokens, image_tokens], dim=1)\n",
    "        positional_embeds = self.positional_encoding(self.num_token)\n",
    "\n",
    "        return positional_embeds\n",
    "\n",
    "\n",
    "class encode_layer(VisonTransformer):\n",
    "    def __init__(self, num_layer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm((self.batch_size, self.num_token, self.embed_hidden_size))\n",
    "        self.mlp = nn.Linear(self.patch_size * self.patch_size * self.num_patch, self.embed_hidden_size)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "\n",
    "class MultiHeadAttention(encode_layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
