{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "# 画像のサイズを定義\n",
    "image_size = 256\n",
    "# バッチサイズを定義\n",
    "batch_size = 32\n",
    "# データのルートディレクトリを指定\n",
    "root_dir = \"./data\"\n",
    "\n",
    "# 画像変換の設定\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(image_size),  # 画像サイズをリサイズ\n",
    "    torchvision.transforms.ToTensor()  # 画像をテンソルに変換\n",
    "])\n",
    "\n",
    "# 訓練データセットをロード\n",
    "train_datasets = torchvision.datasets.CIFAR10(\n",
    "    root=root_dir, train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# 検証データセットをロード\n",
    "val_datasets = torchvision.datasets.CIFAR10(\n",
    "    root=root_dir, train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# 訓練データ用のデータローダーを作成\n",
    "train_dataloader = DataLoader(\n",
    "    train_datasets, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "# 検証データ用のデータローダーを作成\n",
    "val_dataloader = DataLoader(\n",
    "    val_datasets, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([32, 3, 256, 256])\n",
      "2 torch.Size([32, 3, 256, 256])\n",
      "3 torch.Size([32, 3, 256, 256])\n",
      "4 torch.Size([32, 3, 256, 256])\n",
      "5 torch.Size([32, 3, 256, 256])\n",
      "6 torch.Size([32, 3, 256, 256])\n",
      "7 torch.Size([32, 3, 256, 256])\n",
      "8 torch.Size([32, 3, 256, 256])\n",
      "9 torch.Size([32, 3, 256, 256])\n",
      "10 torch.Size([32, 3, 256, 256])\n",
      "11 torch.Size([32, 3, 256, 256])\n",
      "12 torch.Size([32, 3, 256, 256])\n",
      "13 torch.Size([32, 3, 256, 256])\n",
      "14 torch.Size([32, 3, 256, 256])\n",
      "15 torch.Size([32, 3, 256, 256])\n",
      "16 torch.Size([32, 3, 256, 256])\n",
      "17 torch.Size([32, 3, 256, 256])\n",
      "18 torch.Size([32, 3, 256, 256])\n",
      "19 torch.Size([32, 3, 256, 256])\n",
      "20 torch.Size([32, 3, 256, 256])\n",
      "21 torch.Size([32, 3, 256, 256])\n",
      "22 torch.Size([32, 3, 256, 256])\n",
      "23 torch.Size([32, 3, 256, 256])\n",
      "24 torch.Size([32, 3, 256, 256])\n",
      "25 torch.Size([32, 3, 256, 256])\n",
      "26 torch.Size([32, 3, 256, 256])\n",
      "27 torch.Size([32, 3, 256, 256])\n",
      "28 torch.Size([32, 3, 256, 256])\n",
      "29 torch.Size([32, 3, 256, 256])\n",
      "30 torch.Size([32, 3, 256, 256])\n",
      "31 torch.Size([32, 3, 256, 256])\n",
      "32 torch.Size([32, 3, 256, 256])\n",
      "33 torch.Size([32, 3, 256, 256])\n",
      "34 torch.Size([32, 3, 256, 256])\n",
      "35 torch.Size([32, 3, 256, 256])\n",
      "36 torch.Size([32, 3, 256, 256])\n",
      "37 torch.Size([32, 3, 256, 256])\n",
      "38 torch.Size([32, 3, 256, 256])\n",
      "39 torch.Size([32, 3, 256, 256])\n",
      "40 torch.Size([32, 3, 256, 256])\n",
      "41 torch.Size([32, 3, 256, 256])\n",
      "42 torch.Size([32, 3, 256, 256])\n",
      "43 torch.Size([32, 3, 256, 256])\n",
      "44 torch.Size([32, 3, 256, 256])\n",
      "45 torch.Size([32, 3, 256, 256])\n",
      "46 torch.Size([32, 3, 256, 256])\n",
      "47 torch.Size([32, 3, 256, 256])\n",
      "48 torch.Size([32, 3, 256, 256])\n",
      "49 torch.Size([32, 3, 256, 256])\n",
      "50 torch.Size([32, 3, 256, 256])\n",
      "51 torch.Size([32, 3, 256, 256])\n",
      "52 torch.Size([32, 3, 256, 256])\n",
      "53 torch.Size([32, 3, 256, 256])\n",
      "54 torch.Size([32, 3, 256, 256])\n",
      "55 torch.Size([32, 3, 256, 256])\n",
      "56 torch.Size([32, 3, 256, 256])\n",
      "57 torch.Size([32, 3, 256, 256])\n",
      "58 torch.Size([32, 3, 256, 256])\n",
      "59 torch.Size([32, 3, 256, 256])\n",
      "60 torch.Size([32, 3, 256, 256])\n",
      "61 torch.Size([32, 3, 256, 256])\n",
      "62 torch.Size([32, 3, 256, 256])\n",
      "63 torch.Size([32, 3, 256, 256])\n",
      "64 torch.Size([32, 3, 256, 256])\n",
      "65 torch.Size([32, 3, 256, 256])\n",
      "66 torch.Size([32, 3, 256, 256])\n",
      "67 torch.Size([32, 3, 256, 256])\n",
      "68 torch.Size([32, 3, 256, 256])\n",
      "69 torch.Size([32, 3, 256, 256])\n",
      "70 torch.Size([32, 3, 256, 256])\n",
      "71 torch.Size([32, 3, 256, 256])\n",
      "72 torch.Size([32, 3, 256, 256])\n",
      "73 torch.Size([32, 3, 256, 256])\n",
      "74 torch.Size([32, 3, 256, 256])\n",
      "75 torch.Size([32, 3, 256, 256])\n",
      "76 torch.Size([32, 3, 256, 256])\n",
      "77 torch.Size([32, 3, 256, 256])\n",
      "78 torch.Size([32, 3, 256, 256])\n",
      "79 torch.Size([32, 3, 256, 256])\n",
      "80 torch.Size([32, 3, 256, 256])\n",
      "81 torch.Size([32, 3, 256, 256])\n",
      "82 torch.Size([32, 3, 256, 256])\n",
      "83 torch.Size([32, 3, 256, 256])\n",
      "84 torch.Size([32, 3, 256, 256])\n",
      "85 torch.Size([32, 3, 256, 256])\n",
      "86 torch.Size([32, 3, 256, 256])\n",
      "87 torch.Size([32, 3, 256, 256])\n",
      "88 torch.Size([32, 3, 256, 256])\n",
      "89 torch.Size([32, 3, 256, 256])\n",
      "90 torch.Size([32, 3, 256, 256])\n",
      "91 torch.Size([32, 3, 256, 256])\n",
      "92 torch.Size([32, 3, 256, 256])\n",
      "93 torch.Size([32, 3, 256, 256])\n",
      "94 torch.Size([32, 3, 256, 256])\n",
      "95 torch.Size([32, 3, 256, 256])\n",
      "96 torch.Size([32, 3, 256, 256])\n",
      "97 torch.Size([32, 3, 256, 256])\n",
      "98 torch.Size([32, 3, 256, 256])\n",
      "99 torch.Size([32, 3, 256, 256])\n",
      "100 torch.Size([32, 3, 256, 256])\n",
      "101 torch.Size([32, 3, 256, 256])\n",
      "102 torch.Size([32, 3, 256, 256])\n",
      "103 torch.Size([32, 3, 256, 256])\n",
      "104 torch.Size([32, 3, 256, 256])\n",
      "105 torch.Size([32, 3, 256, 256])\n",
      "106 torch.Size([32, 3, 256, 256])\n",
      "107 torch.Size([32, 3, 256, 256])\n",
      "108 torch.Size([32, 3, 256, 256])\n",
      "109 torch.Size([32, 3, 256, 256])\n",
      "110 torch.Size([32, 3, 256, 256])\n",
      "111 torch.Size([32, 3, 256, 256])\n",
      "112 torch.Size([32, 3, 256, 256])\n",
      "113 torch.Size([32, 3, 256, 256])\n",
      "114 torch.Size([32, 3, 256, 256])\n",
      "115 torch.Size([32, 3, 256, 256])\n",
      "116 torch.Size([32, 3, 256, 256])\n",
      "117 torch.Size([32, 3, 256, 256])\n",
      "118 torch.Size([32, 3, 256, 256])\n",
      "119 torch.Size([32, 3, 256, 256])\n",
      "120 torch.Size([32, 3, 256, 256])\n",
      "121 torch.Size([32, 3, 256, 256])\n",
      "122 torch.Size([32, 3, 256, 256])\n",
      "123 torch.Size([32, 3, 256, 256])\n",
      "124 torch.Size([32, 3, 256, 256])\n",
      "125 torch.Size([32, 3, 256, 256])\n",
      "126 torch.Size([32, 3, 256, 256])\n",
      "127 torch.Size([32, 3, 256, 256])\n",
      "128 torch.Size([32, 3, 256, 256])\n",
      "129 torch.Size([32, 3, 256, 256])\n",
      "130 torch.Size([32, 3, 256, 256])\n",
      "131 torch.Size([32, 3, 256, 256])\n",
      "132 torch.Size([32, 3, 256, 256])\n",
      "133 torch.Size([32, 3, 256, 256])\n",
      "134 torch.Size([32, 3, 256, 256])\n",
      "135 torch.Size([32, 3, 256, 256])\n",
      "136 torch.Size([32, 3, 256, 256])\n",
      "137 torch.Size([32, 3, 256, 256])\n",
      "138 torch.Size([32, 3, 256, 256])\n",
      "139 torch.Size([32, 3, 256, 256])\n",
      "140 torch.Size([32, 3, 256, 256])\n",
      "141 torch.Size([32, 3, 256, 256])\n",
      "142 torch.Size([32, 3, 256, 256])\n",
      "143 torch.Size([32, 3, 256, 256])\n",
      "144 torch.Size([32, 3, 256, 256])\n",
      "145 torch.Size([32, 3, 256, 256])\n",
      "146 torch.Size([32, 3, 256, 256])\n",
      "147 torch.Size([32, 3, 256, 256])\n",
      "148 torch.Size([32, 3, 256, 256])\n",
      "149 torch.Size([32, 3, 256, 256])\n",
      "150 torch.Size([32, 3, 256, 256])\n",
      "151 torch.Size([32, 3, 256, 256])\n",
      "152 torch.Size([32, 3, 256, 256])\n",
      "153 torch.Size([32, 3, 256, 256])\n",
      "154 torch.Size([32, 3, 256, 256])\n",
      "155 torch.Size([32, 3, 256, 256])\n",
      "156 torch.Size([32, 3, 256, 256])\n",
      "157 torch.Size([32, 3, 256, 256])\n",
      "158 torch.Size([32, 3, 256, 256])\n",
      "159 torch.Size([32, 3, 256, 256])\n",
      "160 torch.Size([32, 3, 256, 256])\n",
      "161 torch.Size([32, 3, 256, 256])\n",
      "162 torch.Size([32, 3, 256, 256])\n",
      "163 torch.Size([32, 3, 256, 256])\n",
      "164 torch.Size([32, 3, 256, 256])\n",
      "165 torch.Size([32, 3, 256, 256])\n",
      "166 torch.Size([32, 3, 256, 256])\n",
      "167 torch.Size([32, 3, 256, 256])\n",
      "168 torch.Size([32, 3, 256, 256])\n",
      "169 torch.Size([32, 3, 256, 256])\n",
      "170 torch.Size([32, 3, 256, 256])\n",
      "171 torch.Size([32, 3, 256, 256])\n",
      "172 torch.Size([32, 3, 256, 256])\n",
      "173 torch.Size([32, 3, 256, 256])\n",
      "174 torch.Size([32, 3, 256, 256])\n",
      "175 torch.Size([32, 3, 256, 256])\n",
      "176 torch.Size([32, 3, 256, 256])\n",
      "177 torch.Size([32, 3, 256, 256])\n",
      "178 torch.Size([32, 3, 256, 256])\n",
      "179 torch.Size([32, 3, 256, 256])\n",
      "180 torch.Size([32, 3, 256, 256])\n",
      "181 torch.Size([32, 3, 256, 256])\n",
      "182 torch.Size([32, 3, 256, 256])\n",
      "183 torch.Size([32, 3, 256, 256])\n",
      "184 torch.Size([32, 3, 256, 256])\n",
      "185 torch.Size([32, 3, 256, 256])\n",
      "186 torch.Size([32, 3, 256, 256])\n",
      "187 torch.Size([32, 3, 256, 256])\n",
      "188 torch.Size([32, 3, 256, 256])\n",
      "189 torch.Size([32, 3, 256, 256])\n",
      "190 torch.Size([32, 3, 256, 256])\n",
      "191 torch.Size([32, 3, 256, 256])\n",
      "192 torch.Size([32, 3, 256, 256])\n",
      "193 torch.Size([32, 3, 256, 256])\n",
      "194 torch.Size([32, 3, 256, 256])\n",
      "195 torch.Size([32, 3, 256, 256])\n",
      "196 torch.Size([32, 3, 256, 256])\n",
      "197 torch.Size([32, 3, 256, 256])\n",
      "198 torch.Size([32, 3, 256, 256])\n",
      "199 torch.Size([32, 3, 256, 256])\n",
      "200 torch.Size([32, 3, 256, 256])\n",
      "201 torch.Size([32, 3, 256, 256])\n",
      "202 torch.Size([32, 3, 256, 256])\n",
      "203 torch.Size([32, 3, 256, 256])\n",
      "204 torch.Size([32, 3, 256, 256])\n",
      "205 torch.Size([32, 3, 256, 256])\n",
      "206 torch.Size([32, 3, 256, 256])\n",
      "207 torch.Size([32, 3, 256, 256])\n",
      "208 torch.Size([32, 3, 256, 256])\n",
      "209 torch.Size([32, 3, 256, 256])\n",
      "210 torch.Size([32, 3, 256, 256])\n",
      "211 torch.Size([32, 3, 256, 256])\n",
      "212 torch.Size([32, 3, 256, 256])\n",
      "213 torch.Size([32, 3, 256, 256])\n",
      "214 torch.Size([32, 3, 256, 256])\n",
      "215 torch.Size([32, 3, 256, 256])\n",
      "216 torch.Size([32, 3, 256, 256])\n",
      "217 torch.Size([32, 3, 256, 256])\n",
      "218 torch.Size([32, 3, 256, 256])\n",
      "219 torch.Size([32, 3, 256, 256])\n",
      "220 torch.Size([32, 3, 256, 256])\n",
      "221 torch.Size([32, 3, 256, 256])\n",
      "222 torch.Size([32, 3, 256, 256])\n",
      "223 torch.Size([32, 3, 256, 256])\n",
      "224 torch.Size([32, 3, 256, 256])\n",
      "225 torch.Size([32, 3, 256, 256])\n",
      "226 torch.Size([32, 3, 256, 256])\n",
      "227 torch.Size([32, 3, 256, 256])\n",
      "228 torch.Size([32, 3, 256, 256])\n",
      "229 torch.Size([32, 3, 256, 256])\n",
      "230 torch.Size([32, 3, 256, 256])\n",
      "231 torch.Size([32, 3, 256, 256])\n",
      "232 torch.Size([32, 3, 256, 256])\n",
      "233 torch.Size([32, 3, 256, 256])\n",
      "234 torch.Size([32, 3, 256, 256])\n",
      "235 torch.Size([32, 3, 256, 256])\n",
      "236 torch.Size([32, 3, 256, 256])\n",
      "237 torch.Size([32, 3, 256, 256])\n",
      "238 torch.Size([32, 3, 256, 256])\n",
      "239 torch.Size([32, 3, 256, 256])\n",
      "240 torch.Size([32, 3, 256, 256])\n",
      "241 torch.Size([32, 3, 256, 256])\n",
      "242 torch.Size([32, 3, 256, 256])\n",
      "243 torch.Size([32, 3, 256, 256])\n",
      "244 torch.Size([32, 3, 256, 256])\n",
      "245 torch.Size([32, 3, 256, 256])\n",
      "246 torch.Size([32, 3, 256, 256])\n",
      "247 torch.Size([32, 3, 256, 256])\n",
      "248 torch.Size([32, 3, 256, 256])\n",
      "249 torch.Size([32, 3, 256, 256])\n",
      "250 torch.Size([32, 3, 256, 256])\n",
      "251 torch.Size([32, 3, 256, 256])\n",
      "252 torch.Size([32, 3, 256, 256])\n",
      "253 torch.Size([32, 3, 256, 256])\n",
      "254 torch.Size([32, 3, 256, 256])\n",
      "255 torch.Size([32, 3, 256, 256])\n",
      "256 torch.Size([32, 3, 256, 256])\n",
      "257 torch.Size([32, 3, 256, 256])\n",
      "258 torch.Size([32, 3, 256, 256])\n",
      "259 torch.Size([32, 3, 256, 256])\n",
      "260 torch.Size([32, 3, 256, 256])\n",
      "261 torch.Size([32, 3, 256, 256])\n",
      "262 torch.Size([32, 3, 256, 256])\n",
      "263 torch.Size([32, 3, 256, 256])\n",
      "264 torch.Size([32, 3, 256, 256])\n",
      "265 torch.Size([32, 3, 256, 256])\n",
      "266 torch.Size([32, 3, 256, 256])\n",
      "267 torch.Size([32, 3, 256, 256])\n",
      "268 torch.Size([32, 3, 256, 256])\n",
      "269 torch.Size([32, 3, 256, 256])\n",
      "270 torch.Size([32, 3, 256, 256])\n",
      "271 torch.Size([32, 3, 256, 256])\n",
      "272 torch.Size([32, 3, 256, 256])\n",
      "273 torch.Size([32, 3, 256, 256])\n",
      "274 torch.Size([32, 3, 256, 256])\n",
      "275 torch.Size([32, 3, 256, 256])\n",
      "276 torch.Size([32, 3, 256, 256])\n",
      "277 torch.Size([32, 3, 256, 256])\n",
      "278 torch.Size([32, 3, 256, 256])\n",
      "279 torch.Size([32, 3, 256, 256])\n",
      "280 torch.Size([32, 3, 256, 256])\n",
      "281 torch.Size([32, 3, 256, 256])\n",
      "282 torch.Size([32, 3, 256, 256])\n",
      "283 torch.Size([32, 3, 256, 256])\n",
      "284 torch.Size([32, 3, 256, 256])\n",
      "285 torch.Size([32, 3, 256, 256])\n",
      "286 torch.Size([32, 3, 256, 256])\n",
      "287 torch.Size([32, 3, 256, 256])\n",
      "288 torch.Size([32, 3, 256, 256])\n",
      "289 torch.Size([32, 3, 256, 256])\n",
      "290 torch.Size([32, 3, 256, 256])\n",
      "291 torch.Size([32, 3, 256, 256])\n",
      "292 torch.Size([32, 3, 256, 256])\n",
      "293 torch.Size([32, 3, 256, 256])\n",
      "294 torch.Size([32, 3, 256, 256])\n",
      "295 torch.Size([32, 3, 256, 256])\n",
      "296 torch.Size([32, 3, 256, 256])\n",
      "297 torch.Size([32, 3, 256, 256])\n",
      "298 torch.Size([32, 3, 256, 256])\n",
      "299 torch.Size([32, 3, 256, 256])\n",
      "300 torch.Size([32, 3, 256, 256])\n",
      "301 torch.Size([32, 3, 256, 256])\n",
      "302 torch.Size([32, 3, 256, 256])\n",
      "303 torch.Size([32, 3, 256, 256])\n",
      "304 torch.Size([32, 3, 256, 256])\n",
      "305 torch.Size([32, 3, 256, 256])\n",
      "306 torch.Size([32, 3, 256, 256])\n",
      "307 torch.Size([32, 3, 256, 256])\n",
      "308 torch.Size([32, 3, 256, 256])\n",
      "309 torch.Size([32, 3, 256, 256])\n",
      "310 torch.Size([32, 3, 256, 256])\n",
      "311 torch.Size([32, 3, 256, 256])\n",
      "312 torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch, (images, labels) in enumerate(val_dataloader):\n",
    "    print(batch + 1, images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisonTransformer(nn.Module):\n",
    "    def __init__(self, num_classes, batch_size, image_size, num_channel, patch_size, embed_hidden_size, num_layer, num_head, device, MultiHeadAttention, Encoder):\n",
    "        # ビジョン・トランスフォーマーのコンストラクタ\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_channel = num_channel\n",
    "        self.num_patch = int((image_size / patch_size) * (image_size / patch_size))\n",
    "        self.num_token = self.num_patch + 1\n",
    "        self.num_layer = num_layer\n",
    "        self.num_head = num_head\n",
    "        self.cls_id = torch.tensor(0, dtype=torch.long).to(device)\n",
    "        self.cls_embedding = nn.Embedding(1, embed_hidden_size)\n",
    "        self.embed_hidden_size = embed_hidden_size\n",
    "        self.positional_embedding = nn.Embedding(self.num_token, embed_hidden_size)\n",
    "        self.image_embedding = nn.Linear(patch_size * patch_size * self.num_patch, embed_hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm((batch_size, embed_hidden_size))\n",
    "        self.dropout = nn.Dropout(p=0.9)\n",
    "        self.fc = nn.Linear(embed_hidden_size, num_classes)\n",
    "        args = (batch_size, image_size, num_channel, patch_size, embed_hidden_size, num_layer, num_head, device, MultiHeadAttention)\n",
    "        self.setup_layer(num_layer, Encoder, args)\n",
    "\n",
    "    def image_to_token(self, images, patch_size):\n",
    "        # 画像をトークンに変換する関数\n",
    "        batch_size, num_channel, width, height = self.batch_size, self.num_channel, self.image_size, self.image_size\n",
    "\n",
    "        patch_window = torch.ones((patch_size, patch_size), dtype=torch.long)\n",
    "        patch_window = patch_window.unsqueeze(0).expand(num_channel, patch_size, patch_size)\\\n",
    "            .unsqueeze(0).expand(batch_size, num_channel, patch_size, patch_size)\n",
    "\n",
    "        token_list = []\n",
    "        for row_idx in range(0, width, patch_size):\n",
    "            for col_idx in range(0, height, patch_size):\n",
    "                patch = images[:, :, row_idx: row_idx + patch_size, col_idx:col_idx + patch_size]\n",
    "                token_list.append(patch)\n",
    "\n",
    "        token_list = torch.stack(token_list, dim=0).transpose(0, 1).view(batch_size, 256, -1)\n",
    "\n",
    "        return token_list\n",
    "\n",
    "    def positional_encoding(self, num_token):\n",
    "        # 位置エンコーディングを計算する関数\n",
    "        position_ids = torch.tensor(list(range(num_token)), dtype=torch.long).expand(self.batch_size, -1).to(self.device)\n",
    "        positional_embeds = self.positional_embedding(position_ids)\n",
    "\n",
    "        return positional_embeds\n",
    "\n",
    "    def setup_layer(self, num_layer, encoder, args):\n",
    "        # エンコーダーレイヤーを設定する関数\n",
    "        layer_list = []\n",
    "        for _ in range(num_layer):\n",
    "            layer_list.append(encoder(*args).to(self.device))\n",
    "\n",
    "        module_list = nn.ModuleList(layer_list)\n",
    "        self.layer_list = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # フォワードパスを定義する関数\n",
    "        cls_tokens = self.cls_embedding(self.cls_id).unsqueeze(0).expand(self.batch_size, 1, -1)\n",
    "        image_tokens = self.image_to_token(images, self.patch_size)\n",
    "        tokens = torch.cat([cls_tokens, image_tokens], dim=1)  # torch.concat -> torch.catに修正\n",
    "        positional_embeds = self.positional_encoding(self.num_token)\n",
    "        embed_tokens = (tokens + positional_embeds)\n",
    "        encoded_outputs = self.layer_list(embed_tokens)\n",
    "        cls = encoded_outputs[:, 0, :]\n",
    "        layer_norm = self.layer_norm(cls)\n",
    "        dropout = self.dropout(layer_norm)\n",
    "        outputs = self.fc(dropout)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, batch_size, image_size, num_channel, patch_size, embed_hidden_size, num_layer, num_head, device, MultiHeadAttention):\n",
    "        # エンコーダーのコンストラクタ\n",
    "        super().__init()\n",
    "\n",
    "        num_patch = int((image_size / patch_size) * (image_size / patch_size))\n",
    "        num_token = num_patch + 1\n",
    "        self.layer_norm1 = nn.LayerNorm((batch_size, num_token, embed_hidden_size))\n",
    "        self.layer_norm2 = nn.LayerNorm((batch_size, num_token, embed_hidden_size))\n",
    "        self.dropout = nn.Dropout(p=0.9)\n",
    "        self.mlp = nn.Linear(embed_hidden_size, embed_hidden_size)\n",
    "        self.attention_layer = MultiHeadAttention(embed_hidden_size, num_head, device)\n",
    "        self.gelu = nn.GELU().to(device)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        # エンコーダーのフォワードパスを定義する関数\n",
    "        layer_norm1 = self.layer_norm1(tokens)\n",
    "        dropout1 = self.dropout(layer_norm1)\n",
    "        skip1 = tokens\n",
    "        concat_attention = self.attention_layer(dropout1)\n",
    "\n",
    "        outputs_tmp1 = concat_attention + skip1\n",
    "        skip2 = outputs_tmp1\n",
    "        layer_norm2 = self.layer_norm2(outputs_tmp1)\n",
    "        dropout2 = self.dropout(layer_norm2)\n",
    "        mlp = self.gelu(self.mlp(dropout2))\n",
    "        outputs = mlp + skip2\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_hidden_size, num_head, device):\n",
    "        # マルチヘッドアテンションのコンストラクタ\n",
    "        super().__init__()\n",
    "        self.attention_layers = []\n",
    "        self.query_layers = []\n",
    "        self.key_layers = []\n",
    "        self.value_layers = []\n",
    "        self.num_head = num_head\n",
    "        self.embed_hidden_size = embed_hidden_size\n",
    "        self.multi_embed_hidden_size = int(embed_hidden_size / num_head)\n",
    "\n",
    "        self.device = device\n",
    "        self.setup_attention()\n",
    "\n",
    "    def setup_attention(self):\n",
    "        # アテンションのセットアップを行う関数\n",
    "        for number in range(self.num_head):\n",
    "            self.query_layers.append(nn.Linear(self.embed_hidden_size, self.multi_embed_hidden_size).to(self.device))\n",
    "            self.key_layers.append(nn.Linear(self.embed_hidden_size, self.multi_embed_hidden_size).to(self.device))\n",
    "            self.value_layers.append(nn.Linear(self.embed_hidden_size, self.multi_embed_hidden_size).to(self.device))\n",
    "\n",
    "        self.query_layers = nn.ModuleList(self.query_layers)\n",
    "        self.key_layers = nn.ModuleList(self.key_layers)\n",
    "        self.value_layers = nn.ModuleList(self.value_layers)\n",
    "\n",
    "    def output_attention(self, tokens):\n",
    "        # アテンションの計算を行う関数\n",
    "        for number in range(self.num_head):\n",
    "            query = self.query_layers[number](tokens)\n",
    "            key = self.key_layers[number](tokens)\n",
    "            value = self.value_layers[number](tokens)\n",
    "            attention = nn.Softmax(dim=-1)((query @ torch.transpose(key, 1, 2)) / torch.sqrt(torch.tensor(self.multi_embed_hidden_size))) @ value\n",
    "\n",
    "            if number > 0:\n",
    "                concat_attention = torch.cat([concat_attention, attention], dim=-1)  # torch.concat -> torch.catに修正\n",
    "            else:\n",
    "                concat_attention = attention\n",
    "\n",
    "        return concat_attention\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        # フォワードパスを定義する関数\n",
    "        concat_attention = self.output_attention(tokens)\n",
    "\n",
    "        return concat_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Train Epoch: 1/1 train_loss: 0.09938900172710419 train_correct: 0.0078125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09826721251010895 train_correct: 0.005859375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10128515958786011 train_correct: 0.005533854166666667\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09919302351772785 train_correct: 0.005126953125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0985305905342102 train_correct: 0.0046875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09787710011005402 train_correct: 0.004557291666666667\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09641868727547782 train_correct: 0.004603794642857143\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09696859028190374 train_correct: 0.004638671875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09915352198812696 train_correct: 0.004231770833333333\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09970039427280426 train_correct: 0.0041015625\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10100206190889532 train_correct: 0.003995028409090909\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10130457083384196 train_correct: 0.00390625\n",
      "Step: Train Epoch: 1/1 train_loss: 0.099821765262347 train_correct: 0.004131610576923077\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10163356097681182 train_correct: 0.003976004464285714\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10071193128824234 train_correct: 0.004036458333333334\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10033860709518194 train_correct: 0.0040283203125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10037468242294648 train_correct: 0.00407858455882353\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10089208765162362 train_correct: 0.004123263888888889\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10196912131811443 train_correct: 0.00390625\n",
      "Step: Train Epoch: 1/1 train_loss: 0.102175522595644 train_correct: 0.00380859375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1021226438738051 train_correct: 0.003673735119047619\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10245221853256226 train_correct: 0.0036843039772727275\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10295588490755661 train_correct: 0.0035665760869565215\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1024565293143193 train_correct: 0.003662109375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10227960616350174 train_correct: 0.0035546875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10258076827113445 train_correct: 0.003605769230769231\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10289133892015175 train_correct: 0.003689236111111111\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10314292753381389 train_correct: 0.0035923549107142855\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10379459195095918 train_correct: 0.0035695043103448278\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10400001332163811 train_correct: 0.003515625\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10408872606292847 train_correct: 0.0034967237903225806\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10404243669472635 train_correct: 0.00347900390625\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10416602072390643 train_correct: 0.0034327651515151515\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1043622068622533 train_correct: 0.00341796875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10454835231815066 train_correct: 0.003404017857142857\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10471057250267929 train_correct: 0.0033365885416666665\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10435581167001982 train_correct: 0.003325591216216216\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10459220291752565 train_correct: 0.003315172697368421\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10456459396160565 train_correct: 0.0033553685897435895\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10505120102316141 train_correct: 0.0032958984375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10521888006024244 train_correct: 0.0032631478658536584\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10508178209974653 train_correct: 0.0032784598214285715\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10534262275973032 train_correct: 0.003247638081395349\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10535850596021522 train_correct: 0.0031960227272727275\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10531343387232886 train_correct: 0.003168402777777778\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10515187842690427 train_correct: 0.0031844429347826085\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10509071879564448 train_correct: 0.0031790226063829786\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10559009341523051 train_correct: 0.0031331380208333335\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10555741525426203 train_correct: 0.003128985969387755\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10579907581210136 train_correct: 0.00314453125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10578813053229276 train_correct: 0.0031020220588235292\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10572233151357907 train_correct: 0.003117487980769231\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10569315909777048 train_correct: 0.0030955188679245285\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10581046798162991 train_correct: 0.003074363425925926\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10554225973107598 train_correct: 0.003107244318181818\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10541971826127597 train_correct: 0.0031040736607142855\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10534847553884774 train_correct: 0.003135279605263158\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1051587777148033 train_correct: 0.0030980603448275863\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10523758462425005 train_correct: 0.003078654661016949\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10520221963524819 train_correct: 0.003076171875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1051905125868125 train_correct: 0.0030577612704918034\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10552960033378293 train_correct: 0.003039944556451613\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10539397195218102 train_correct: 0.0030381944444444445\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10548664443194866 train_correct: 0.003021240234375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10543620460308516 train_correct: 0.003019831730769231\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10531518574465405 train_correct: 0.0030036695075757575\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10541377839312624 train_correct: 0.0030025652985074627\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10526530477492248 train_correct: 0.003030215992647059\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10544000846752222 train_correct: 0.0030146059782608695\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10562697457415716 train_correct: 0.0030133928571428573\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10554200820100139 train_correct: 0.0029984595070422534\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1055897247667114 train_correct: 0.002997504340277778\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10532063317217238 train_correct: 0.002983197773972603\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10523668475247719 train_correct: 0.002982474662162162\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10510913908481598 train_correct: 0.0029817708333333332\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10479653048280038 train_correct: 0.003032483552631579\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10491408030321071 train_correct: 0.003043831168831169\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10520383686973499 train_correct: 0.0030298477564102565\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10507926976756204 train_correct: 0.0030533030063291137\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10495203714817762 train_correct: 0.0031005859375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10465079895508142 train_correct: 0.0031225887345679012\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10460090628120958 train_correct: 0.003120236280487805\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10446089506149292 train_correct: 0.0031297063253012047\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10440592982229732 train_correct: 0.003138950892857143\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10415657618466545 train_correct: 0.003159466911764706\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10394189480778783 train_correct: 0.003190861191860465\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10388875153215452 train_correct: 0.0031654094827586205\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10388211050832813 train_correct: 0.003207120028409091\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10378984956259138 train_correct: 0.003204002808988764\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10375437157021629 train_correct: 0.0032118055555555554\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10350227879953909 train_correct: 0.003230168269230769\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10335926006993522 train_correct: 0.003237516983695652\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10320261929945279 train_correct: 0.0032447076612903227\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10306798975835456 train_correct: 0.0032413563829787233\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10303351604624798 train_correct: 0.003227796052631579\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10292349670392771 train_correct: 0.0032246907552083335\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10284816235611119 train_correct: 0.003241784793814433\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10286815996680941 train_correct: 0.003218670280612245\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10282059367557969 train_correct: 0.003235479797979798\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10284213595092297 train_correct: 0.00322265625\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10286105520064288 train_correct: 0.003210086633663366\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10290797171639461 train_correct: 0.0031977634803921568\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10285984471584987 train_correct: 0.0031856796116504853\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1028357557952404 train_correct: 0.0032019981971153845\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10273558582578386 train_correct: 0.003199404761904762\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10271433487815677 train_correct: 0.0031968602594339623\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10272509945887272 train_correct: 0.003176109813084112\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1025828651531979 train_correct: 0.003200954861111111\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10253754545242415 train_correct: 0.003189506880733945\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10243690142577344 train_correct: 0.0031871448863636364\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1023893571114755 train_correct: 0.00317602759009009\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10253671456926636 train_correct: 0.003173828125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10249484752395512 train_correct: 0.0031975940265486728\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10242058454375517 train_correct: 0.003203810307017544\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10239232499962268 train_correct: 0.0032099184782608697\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10230795685844175 train_correct: 0.003207502693965517\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10205356209960759 train_correct: 0.003230168269230769\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10202749338695559 train_correct: 0.003235897775423729\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10208671571326856 train_correct: 0.0032251181722689074\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10194128751754761 train_correct: 0.0032063802083333332\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10193312223538879 train_correct: 0.003204093491735537\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10187211883116941 train_correct: 0.0032178534836065573\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10190276444200577 train_correct: 0.003199631605691057\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10190348501407331 train_correct: 0.003189579133064516\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10187512838840485 train_correct: 0.0031953125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10183996245974586 train_correct: 0.003193204365079365\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1018813091704226 train_correct: 0.0031834399606299212\n",
      "Step: Train Epoch: 1/1 train_loss: 0.101837549416814 train_correct: 0.00316619873046875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10177769021008366 train_correct: 0.0031795058139534884\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10169989650066082 train_correct: 0.0031700721153846154\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10168024653014336 train_correct: 0.0031607824427480917\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10173540500303109 train_correct: 0.003144235321969697\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10165459057666305 train_correct: 0.003157307330827068\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10166165182617173 train_correct: 0.0031410331156716416\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10162695563501782 train_correct: 0.0031394675925925926\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1016066606320879 train_correct: 0.003130744485294118\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1014920113077999 train_correct: 0.003143533302919708\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1013934391996135 train_correct: 0.0031490602355072465\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10132133188865168 train_correct: 0.003154507643884892\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10126288245831216 train_correct: 0.0031459263392857144\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1012464388148159 train_correct: 0.003137466755319149\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10122896101273282 train_correct: 0.003129126320422535\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10117356604212648 train_correct: 0.0031345607517482515\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10114857425085372 train_correct: 0.003139919704861111\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1010410893066176 train_correct: 0.0031519396551724136\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10099614151332477 train_correct: 0.003143728595890411\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10090054738886502 train_correct: 0.0031422725340136052\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10086272375003712 train_correct: 0.0031474345439189188\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10078412074370673 train_correct: 0.003159081375838926\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10069868365923564 train_correct: 0.0031510416666666666\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10067080400440077 train_correct: 0.0031495757450331124\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10056628610350583 train_correct: 0.003180252878289474\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10054716263331619 train_correct: 0.0031977634803921568\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10056171895234615 train_correct: 0.0031960227272727275\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10045884929357037 train_correct: 0.0032006048387096774\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10042351641907142 train_correct: 0.003186348157051282\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10037239242321366 train_correct: 0.0031784932324840764\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10043910320235204 train_correct: 0.0031645569620253164\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10040673065298009 train_correct: 0.0031630797955974842\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1004153317771852 train_correct: 0.003155517578125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10041787979765708 train_correct: 0.003148049301242236\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10035900932587223 train_correct: 0.00316478587962963\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10032093442656512 train_correct: 0.0031873082822085888\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10025313373927663 train_correct: 0.0031976467225609756\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10018047911651207 train_correct: 0.0032078598484848483\n",
      "Step: Train Epoch: 1/1 train_loss: 0.1001314401895885 train_correct: 0.003194418298192771\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10004931884611439 train_correct: 0.003198680763473054\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10000818484418449 train_correct: 0.003197079613095238\n",
      "Step: Train Epoch: 1/1 train_loss: 0.10003571507669765 train_correct: 0.0031954974112426036\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09993146355537808 train_correct: 0.0031939338235294117\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09988367391957177 train_correct: 0.003180966739766082\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09980163848850616 train_correct: 0.0031681504360465116\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0997310965994879 train_correct: 0.003161127167630058\n",
      "Step: Train Epoch: 1/1 train_loss: 0.099670576252814 train_correct: 0.0031541846264367818\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09962348073720932 train_correct: 0.0031417410714285714\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09954495397819714 train_correct: 0.0031516335227272725\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0994969565147734 train_correct: 0.003155896892655367\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09946004167366564 train_correct: 0.0031546260533707863\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0993809586380447 train_correct: 0.0031424581005586594\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09930534151693185 train_correct: 0.003146701388888889\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09929164918911391 train_correct: 0.0031455024171270717\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0992591136268207 train_correct: 0.003160413804945055\n",
      "Step: Train Epoch: 1/1 train_loss: 0.099260945382014 train_correct: 0.0031538165983606556\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09928207884988059 train_correct: 0.0031472911005434785\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09925590266247053 train_correct: 0.0031355574324324325\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09918973034107557 train_correct: 0.003139700940860215\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09910350512055789 train_correct: 0.0031385778743315508\n",
      "Step: Train Epoch: 1/1 train_loss: 0.099005529696637 train_correct: 0.0031634391622340427\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09896789711934549 train_correct: 0.003167369378306878\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09901844086615663 train_correct: 0.0031609786184210527\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09907799725133087 train_correct: 0.003154654777486911\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09906530605318646 train_correct: 0.0031483968098958335\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09902494667107577 train_correct: 0.0031472636010362693\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09898645761086769 train_correct: 0.0031411082474226805\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09895287664272846 train_correct: 0.0031450320512820514\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09894683744226183 train_correct: 0.003133968431122449\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09895349184268622 train_correct: 0.003118059961928934\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09894111455239431 train_correct: 0.003112176452020202\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09887126597327803 train_correct: 0.003125981469849246\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09887601669877767 train_correct: 0.003115234375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09884443326820781 train_correct: 0.0031143112562189053\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09881775309838871 train_correct: 0.0031085628094059408\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09876077684569241 train_correct: 0.0031076816502463053\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09869854517427146 train_correct: 0.003130744485294118\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09868897719354164 train_correct: 0.0031297637195121953\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09861681349937199 train_correct: 0.003114570691747573\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09856725214184195 train_correct: 0.003113677536231884\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09854345460637258 train_correct: 0.00311279296875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09852093522343339 train_correct: 0.003107244318181818\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09841510202913058 train_correct: 0.0031203497023809526\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09836972900335257 train_correct: 0.0031287026066350713\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09831048281125303 train_correct: 0.003132370283018868\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09829832928281435 train_correct: 0.00312224911971831\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09822454703884705 train_correct: 0.003125912675233645\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09823554823564928 train_correct: 0.0031204578488372094\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09821365594311997 train_correct: 0.003128616898148148\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09815727012910051 train_correct: 0.003132200460829493\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09811989402552264 train_correct: 0.0031357511467889907\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09807722233065731 train_correct: 0.003143728595890411\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09806769920343703 train_correct: 0.003133877840909091\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09805767733721711 train_correct: 0.0031329539027149323\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09806924511317734 train_correct: 0.003123240427927928\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09804693004742866 train_correct: 0.003117993273542601\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09801545649367784 train_correct: 0.00311279296875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09800122125281228 train_correct: 0.003107638888888889\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0979351551989011 train_correct: 0.003106851493362832\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09786156489460479 train_correct: 0.00312758122246696\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09781731635724243 train_correct: 0.0031267132675438596\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09780995459926181 train_correct: 0.003121588427947598\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09777568692098493 train_correct: 0.0031207540760869565\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09773465616878493 train_correct: 0.003119926948051948\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09767619427293539 train_correct: 0.003123316271551724\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09763571520859592 train_correct: 0.003114102736051502\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09763139744217579 train_correct: 0.0031091412927350425\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09760156204091741 train_correct: 0.003112533244680851\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09756946869952193 train_correct: 0.003111758474576271\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0975298798851323 train_correct: 0.003115110759493671\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09747009020016975 train_correct: 0.003126641281512605\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09743319486100305 train_correct: 0.0031380753138075313\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09740685978904366 train_correct: 0.0031412760416666668\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09732495415260188 train_correct: 0.0031444502074688798\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0973034252620433 train_correct: 0.003143562758264463\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09727681550837348 train_correct: 0.003142682613168724\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09722669566141777 train_correct: 0.0031378073770491803\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09717922715508208 train_correct: 0.003125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09713373221154135 train_correct: 0.0031242060467479675\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0970441739146526 train_correct: 0.003135279605263158\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09699817127998799 train_correct: 0.0031305128528225806\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0969238668740035 train_correct: 0.003137550200803213\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09687433603405952 train_correct: 0.00314453125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09686825273046455 train_correct: 0.0031514566733067727\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0968113692979964 train_correct: 0.003154451884920635\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09675668551045444 train_correct: 0.003157423418972332\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09672158258402441 train_correct: 0.0031603715551181103\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09673394408880495 train_correct: 0.0031518075980392158\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09668008732842281 train_correct: 0.003162384033203125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09663470367745203 train_correct: 0.003157678745136187\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09657123863928077 train_correct: 0.0031492248062015503\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09655197439391641 train_correct: 0.0031521476833976836\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0965369036851021 train_correct: 0.0031512920673076924\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09652166131355754 train_correct: 0.0031504430076628354\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09647308949750798 train_correct: 0.003149600429389313\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09642232110291833 train_correct: 0.003141337927756654\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09639217360227396 train_correct: 0.0031331380208333335\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09634837418232324 train_correct: 0.003128685141509434\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09631832210080964 train_correct: 0.003127937030075188\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09630735531058651 train_correct: 0.00312719452247191\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09634185095887575 train_correct: 0.0031155258861940297\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09631399394854294 train_correct: 0.003125726068773234\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09630788065217159 train_correct: 0.003125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09629115511790413 train_correct: 0.0031170721863468635\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09627635598949649 train_correct: 0.0031092026654411763\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09623745255745374 train_correct: 0.0031121222527472525\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09616254748654192 train_correct: 0.0031150205291970803\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0961016437140378 train_correct: 0.003107244318181818\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0960406026924434 train_correct: 0.003110139266304348\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09604499674661064 train_correct: 0.0030989113267148012\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09602714597964458 train_correct: 0.0030947897931654675\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09600920956515069 train_correct: 0.003097698252688172\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09598358441144228 train_correct: 0.0030936104910714284\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0959614456177182 train_correct: 0.0030895518238434165\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09595462819891619 train_correct: 0.003078595966312057\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09590273471582063 train_correct: 0.00308497128975265\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0958535724227697 train_correct: 0.0030947403169014087\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09579276060848906 train_correct: 0.003101014254385965\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09575887845008524 train_correct: 0.0030970006555944055\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09569486578478631 train_correct: 0.0030998203397212543\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09570714169078404 train_correct: 0.0031026204427083335\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09568911352578331 train_correct: 0.0031054011678200693\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09567647666252893 train_correct: 0.003101427801724138\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09564835217195689 train_correct: 0.0031075493986254294\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09563146661711883 train_correct: 0.003100251498287671\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09559506973817487 train_correct: 0.0031030023464163822\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09555421245037293 train_correct: 0.0031024128401360546\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09551215348607403 train_correct: 0.0031018273305084745\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09548486726408875 train_correct: 0.0031012457770270272\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0954601963862827 train_correct: 0.00310066813973064\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09547023267653965 train_correct: 0.0030968173238255033\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09540627759734922 train_correct: 0.0031060566471571905\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09542143533627193 train_correct: 0.0031022135416666667\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0953710537861748 train_correct: 0.003101640365448505\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09535206444808189 train_correct: 0.003104304635761589\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09533018500793099 train_correct: 0.0031005053630363036\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09530422339019806 train_correct: 0.0031031558388157896\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09527856893226748 train_correct: 0.0031025870901639344\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09524559120044988 train_correct: 0.003098830678104575\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09524771544463471 train_correct: 0.0030950987377850164\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09522079122434189 train_correct: 0.003097732345779221\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09519934200931907 train_correct: 0.0030940281148867316\n",
      "Step: Train Epoch: 1/1 train_loss: 0.095192463335491 train_correct: 0.003087197580645161\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09514831325153063 train_correct: 0.0030961113344051445\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09512666376450887 train_correct: 0.0030987079326923075\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0950727820539246 train_correct: 0.003104407947284345\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09504490464356295 train_correct: 0.0031131817277070062\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09503105164520324 train_correct: 0.003103298611111111\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09500168270985537 train_correct: 0.0030996588212025317\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09497244945177896 train_correct: 0.0030991226340694004\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09492342075649297 train_correct: 0.00309858981918239\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09489401735855868 train_correct: 0.0030949990203761758\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09482414096128196 train_correct: 0.003106689453125\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09482136886346378 train_correct: 0.0031030957943925233\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09478362941223642 train_correct: 0.003105590062111801\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09474310777135678 train_correct: 0.0031050454721362228\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09469758914668619 train_correct: 0.0031045042438271604\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09470407978846476 train_correct: 0.0031009615384615385\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09465590898701749 train_correct: 0.0031034317484662575\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09462910867794573 train_correct: 0.0031029004204892966\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09459426665178887 train_correct: 0.003105349657012195\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09458621430541969 train_correct: 0.003101847454407295\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09458280639214948 train_correct: 0.0030983664772727274\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0945460932087322 train_correct: 0.0031008072129909366\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09452881659549403 train_correct: 0.0031002917921686747\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09448316080255194 train_correct: 0.0031115099474474475\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09444506156319629 train_correct: 0.003113889408682635\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09441451483698034 train_correct: 0.0031104244402985074\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0943965290540031 train_correct: 0.0031069800967261905\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09438687087608728 train_correct: 0.0031006583827893177\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09435838277964197 train_correct: 0.003108820266272189\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09433306533854267 train_correct: 0.0031140532817109145\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09429452531039714 train_correct: 0.0031221277573529414\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09427841381330994 train_correct: 0.0031215634164222872\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09425257573350829 train_correct: 0.0031238578216374268\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09423675353342868 train_correct: 0.003120444606413994\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0942243593203467 train_correct: 0.003114212390988372\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0941940033349438 train_correct: 0.003113677536231884\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09416807490277153 train_correct: 0.003113145773121387\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09413875242217473 train_correct: 0.003112617074927954\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09409080349422734 train_correct: 0.003114897629310345\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0940760469496421 train_correct: 0.003114366941260745\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09403282582759857 train_correct: 0.003119419642857143\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09403939583362678 train_correct: 0.003116096866096866\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09406135493720119 train_correct: 0.00311279296875\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09404906345578834 train_correct: 0.0031122742563739376\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09403593907669439 train_correct: 0.0031089998234463275\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09400773325436552 train_correct: 0.0031084947183098594\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09399294376038433 train_correct: 0.0031162219101123594\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09397944432346761 train_correct: 0.0031102284663865544\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09396534771060144 train_correct: 0.0031069963337988825\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09395939983365263 train_correct: 0.0030983417479108636\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0939260766737991 train_correct: 0.0031005859375\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09392497618360203 train_correct: 0.0030974073753462605\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09392214873136737 train_correct: 0.0030942463743093922\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0939123133202558 train_correct: 0.003096483298898072\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09386457535591754 train_correct: 0.0030987079326923075\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09385359156621645 train_correct: 0.0030928938356164382\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09381778599297413 train_correct: 0.0031057889344262295\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09379850242703097 train_correct: 0.00310530909400545\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0937571172076075 train_correct: 0.0031074855638586955\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09374514999509181 train_correct: 0.0030990641937669377\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09374196926081503 train_correct: 0.0031012457770270272\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09373466640389512 train_correct: 0.0030955188679245285\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09370609865553918 train_correct: 0.0030950730846774194\n",
      "Step: Train Epoch: 1/1 train_loss: 0.0937202399641515 train_correct: 0.0030893934316353886\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09371995674894455 train_correct: 0.0030889664104278075\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09372019052505492 train_correct: 0.0030911458333333333\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09367695369539743 train_correct: 0.003095910904255319\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09368052412644622 train_correct: 0.0030954699933687002\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09365674463056382 train_correct: 0.003089864417989418\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09365328564492882 train_correct: 0.003086865105540897\n",
      "Step: Train Epoch: 1/1 train_loss: 0.09362931098592908 train_correct: 0.003086451480263158\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torcheval.metrics.functional import (multiclass_accuracy, \n",
    "                                          multiclass_precision,\n",
    "                                          multiclass_recall,\n",
    "                                          multiclass_f1_score\n",
    "                                          )\n",
    "\n",
    "# デバイスを選択 (GPUが利用可能な場合はGPUを使用し、そうでなければCPUを使用)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデルの設定とハイパーパラメータ\n",
    "kwargs = {\n",
    "    \"num_classes\": 10, \n",
    "    \"batch_size\": 32, \n",
    "    \"image_size\": 256, \n",
    "    \"num_channel\": 3, \n",
    "    \"patch_size\": 16, \n",
    "    \"embed_hidden_size\": 768,\n",
    "    \"num_layer\": 12, \n",
    "    \"num_head\": 8,\n",
    "    \"device\": device,\n",
    "    \"MultiHeadAttention\": MultiHeadAttention, \n",
    "    \"Encoder\": Encoder\n",
    "}\n",
    "\n",
    "# モデルを初期化し、デバイスに配置\n",
    "model = VisonTransformer(**kwargs).to(device)\n",
    "\n",
    "# 損失関数 (CrossEntropyLoss) の設定\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# オプティマイザ (Adam) の設定\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# モデルの出力を保存するディレクトリ\n",
    "output_dir = \"./output\"\n",
    "\n",
    "# 訓練中の損失と正解率、精度、再現率、F1スコアを記録するためのリスト\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_correct_list = []\n",
    "val_correct_list = []\n",
    "presision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# エポック数\n",
    "epochs = 1\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size = kwargs[\"batch_size\"]\n",
    "\n",
    "# 最小の損失を初期化\n",
    "min_loss = float('inf')\n",
    "\n",
    "# エポックのループ\n",
    "for epoch in range(epochs):\n",
    "    # \"train\"と\"val\"の2つのステップでループ\n",
    "    for step in [\"train\", \"val\"]:\n",
    "        if step == \"train\":\n",
    "            model.train()\n",
    "            dataloader = train_dataloader\n",
    "        else:\n",
    "            model.eval()\n",
    "            dataloader = val_dataloader\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "\n",
    "        # ミニバッチのループ\n",
    "        for batch, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(model.training):\n",
    "                outputs = model(images)\n",
    "                pred = torch.argmax(outputs, dim=-1)\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                correct = multiclass_accuracy(\n",
    "                    input=outputs,\n",
    "                    target=labels,\n",
    "                    num_classes=kwargs[\"num_classes\"],\n",
    "                    average=\"micro\"\n",
    "                )\n",
    "\n",
    "                if model.training:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() / batch_size\n",
    "            running_correct += correct.item() / batch_size\n",
    "\n",
    "            if model.training:\n",
    "                train_loss_list.append(running_loss)\n",
    "                train_correct_list.append(running_correct)\n",
    "                print(f\"Step: Train Epoch: {epoch + 1}/{epochs} train_loss: {running_loss / (batch + 1)} train_correct: {running_correct / (batch + 1)}\")\n",
    "            else:\n",
    "                print(f\"Step: Train Epoch: {epoch + 1}/{epochs} val_loss: {running_loss / (batch + 1)} val_correct: {running_correct / (batch + 1)}\")\n",
    "                val_loss_list.append(running_loss)\n",
    "                val_correct_list.append(running_correct)\n",
    "                \n",
    "                # 精度、再現率、F1スコアの計算\n",
    "                precision = multiclass_precision(\n",
    "                    input=outputs,\n",
    "                    target=labels,\n",
    "                    num_classes=kwargs[\"num_classes\"],\n",
    "                    average=\"micro\"\n",
    "                ).item()\n",
    "\n",
    "                recall = multiclass_recall(\n",
    "                    input=outputs,\n",
    "                    target=labels,\n",
    "                    num_classes=kwargs[\"num_classes\"],\n",
    "                    average=\"micro\"\n",
    "                ).item()\n",
    "\n",
    "                f1_score = multiclass_f1_score(\n",
    "                    input=outputs,\n",
    "                    target=labels,\n",
    "                    num_classes=kwargs[\"num_classes\"],\n",
    "                    average=\"micro\"\n",
    "                ).item()\n",
    "\n",
    "                recall_list.append(recall)\n",
    "                presision_list.append(precision)\n",
    "                f1_list.append(f1_score)\n",
    "\n",
    "    if running_loss < min_loss:\n",
    "        print(\"Model Save!\")\n",
    "        min_loss = running_loss\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir) \n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, f\"{batch + 1}.pth\"))  # モデルを指定したディレクトリに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
